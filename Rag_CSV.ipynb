{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4f3XLG0Ru/jnPbq8If322",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beyg1/Q3/blob/main/Rag_CSV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cgc1eDvyLFfQ"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain chromadb langchain_community langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Import Required Modules\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import CSVLoader\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "vQhD5lHjTtD0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Download the dataset and load it locally\n",
        "import requests\n",
        "\n",
        "\n",
        "file_path = '/content/travel_destination_guide.csv'\n",
        "\n",
        "loader = CSVLoader(file_path='/content/travel_destination_guide.csv')\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "K_T8wJOEUNu7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6Y0LtBuFlB2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "pages = [doc.page_content for doc in documents] #Extract page-content from doc\n",
        "# Initialize character text splitter\n",
        "text_splitter = CharacterTextSplitter(chunk_size=500,chunk_overlap=0)\n",
        "chunks = text_splitter.create_documents(pages)\n",
        "print(f\"Number of Chunks: {len(chunks)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW1WJSUiO04K",
        "outputId": "68f6c4bc-9d4c-4e45-f30c-12068f5d8c7e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Chunks: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yneeKwZxRhV4",
        "outputId": "66ba92fe-a629-498e-91ee-540f82fc6561"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={}, page_content='Destination: Destination 1\\nActivities: Activity 1, Activity 2, Activity 3\\nClimate: Warm\\nDescription: Description for Destination 1')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Initialize Embeddings\n",
        "from google.colab import userdata\n",
        "key = userdata.get('GOOGLE_API_KEY')\n",
        "embedding_model = GoogleGenerativeAIEmbeddings(google_api_key=key,  model=\"models/text-embedding-004\")"
      ],
      "metadata": {
        "id": "Xer_v9cXUd-D"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Create a Chroma Vector Store\n",
        "vector_store = Chroma.from_documents(documents, embedding=embedding_model)"
      ],
      "metadata": {
        "id": "Z-HuFMueUq7v"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(google_api_key=key,\n",
        "                                   model=\"gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "xUiPn84aUv4Z"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
        "\n",
        "print(type(retriever))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZF43t9KUzkf",
        "outputId": "af6880bb-b89a-4df4-aebd-a5683968b760"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_core.vectorstores.base.VectorStoreRetriever'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_docs = retriever.get_relevant_documents(\"Climate\")\n",
        "for doc in sample_docs:\n",
        "    print(doc.page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mXT-mHSU9tE",
        "outputId": "b3601fc2-51f7-45f5-fc3f-19e34af87f16"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-bb4ea4d1bfcc>:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  sample_docs = retriever.get_relevant_documents(\"Climate\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Destination: Destination 123\n",
            "Activities: Activity 3, Activity 4, Activity 5\n",
            "Climate: Cold\n",
            "Description: Description for Destination 123\n",
            "Destination: Destination 141\n",
            "Activities: Activity 1, Activity 2, Activity 3\n",
            "Climate: Cold\n",
            "Description: Description for Destination 141\n",
            "Destination: Destination 147\n",
            "Activities: Activity 7, Activity 8, Activity 9\n",
            "Climate: Cold\n",
            "Description: Description for Destination 147\n",
            "Destination: Destination 144\n",
            "Activities: Activity 4, Activity 5, Activity 6\n",
            "Climate: Cold\n",
            "Description: Description for Destination 144\n",
            "Destination: Destination 102\n",
            "Activities: Activity 2, Activity 3, Activity 4\n",
            "Climate: Cold\n",
            "Description: Description for Destination 102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "chat_template = ChatPromptTemplate.from_messages([\n",
        "    # System Message Prompt Template\n",
        "    SystemMessage(content=\"\"\"You are a Helpful Travel Agent.\n",
        "                  Given a context and question from user,\n",
        "                  you should answer based on the given context.\"\"\"),\n",
        "    # Human Message Prompt Template\n",
        "    HumanMessagePromptTemplate.from_template(\"\"\"Answer the question based on the given context.\n",
        "    Context: {context}\n",
        "    Question: {question}\n",
        "    Answer: \"\"\")\n",
        "])\n",
        "\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | chat_template\n",
        "    | llm\n",
        "    | output_parser\n",
        ")"
      ],
      "metadata": {
        "id": "VPdAMPbnVC1c"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Irrelevant retreival\n",
        "response = rag_chain.invoke(\"\"\"Please summarize Leave No Context Behind:\n",
        "                             Efficient Infinite Context Transformers with Infini-attention\"\"\")\n",
        "\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "qj7Fy3fRVFon",
        "outputId": "df7d3579-d94a-4306-e525-e884f8ec770c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I\\'m sorry, but the provided text gives information about various travel destinations but contains no information about \"Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention\".  Therefore, I cannot answer your question.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke(\"\"\"What are top 3 destinations with warm climate and fun activities?\"\"\")\n",
        "\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "5l4qichqVN9M",
        "outputId": "d4239df2-78db-40bb-cc80-bee7a16fc42e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Based on the provided text, the top 3 destinations with a warm climate and fun activities are Destination 391, Destination 331, and Destination 361.  They all share Activities 1, 2, and 3, and have a warm climate.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Set Up Retrieval-Augmented Generation (RAG) Chain\n",
        "from langchain.chains import RetrievalQA\n",
        "faq_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever,chain_type=\"stuff\",)"
      ],
      "metadata": {
        "id": "1LpdPPcyVT68"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Ask a Question\n",
        "question = \"Suggest Top destination with moderate climate\"\n",
        "response = faq_chain.run(question)\n",
        "\n",
        "print(\"Response:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voNCYjn2VaUF",
        "outputId": "baf2e920-8988-4ddf-8bcc-5fbb4d604159"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: Based on the provided data, I cannot definitively say which is the \"top\" destination with a moderate climate, as there is no ranking or preference information given.  However, Destinations 2, 92, and 62 all have moderate climates.\n"
          ]
        }
      ]
    }
  ]
}