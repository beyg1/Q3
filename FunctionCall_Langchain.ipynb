{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDrXYAvAkjSF+MmdX3gsye",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beyg1/Q3/blob/main/FunctionCall_Langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hHX6CvFimfYh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b7deb94-a0d4-4a93-a258-287458cefeb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m41.0/41.7 kB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m868.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U langchain-google-genai # google's generative ai installation with langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata #importing gemini key\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "#connecting LLM\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "llm.invoke(\"sup\")"
      ],
      "metadata": {
        "id": "7SYbXARNnoR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bad59e69-2a2a-484c-de26-61631807feb7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Sup yourself!  How's it going?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-63e44add-d80e-4ae7-ba23-fe0d2660ead8-0', usage_metadata={'input_tokens': 2, 'output_tokens': 11, 'total_tokens': 13, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tool/Function Calling\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def func1(i:int):\n",
        "  \"\"\"Return Function1\"\"\"\n",
        "  return i+50/10\n",
        "tools = [func1]"
      ],
      "metadata": {
        "id": "oXWbRfGXn1Aw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#A tool func1 hasbeen created but hasnt been passed to the llm. that's why no answer\n",
        "llm.invoke(\"What is Function1 of 1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SUhj096pIm5",
        "outputId": "21e7c2a7-d511-4703-a69c-2122212849a5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='\"Function1 of 1\" isn\\'t a standard mathematical or programming term.  It\\'s likely referring to a specific context, such as:\\n\\n* **A numbered function in a list or sequence:**  There\\'s only one function, and it\\'s the first (and only) one.  This is common in documentation or code where multiple functions are described.\\n\\n* **Progress indicator:**  It might be part of a progress bar or status update indicating that one out of one function has completed.\\n\\n* **Part of a filename or identifier:**  It\\'s possible this is a portion of a longer name, like `Function1_of_1.py` which suggests a Python file.\\n\\nWithout more information about where you encountered this phrase, it\\'s impossible to give a more precise answer.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-ee86ef7f-cdbf-42f9-a9a0-4b7382e5f0de-0', usage_metadata={'input_tokens': 8, 'output_tokens': 169, 'total_tokens': 177, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_tools = llm.bind_tools(tools) ## Bind tools to the LLM"
      ],
      "metadata": {
        "id": "VOr9B0ajp1WP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_tools.invoke(\"What is func1 for 1\") #llm now recognizez the tool/func called but still no content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaDAFTh5qFsg",
        "outputId": "f45aac57-0974-4e81-dc53-9b8d0b9cf0ad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'name': 'func1', 'arguments': '{\"i\": 1.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-54058c91-bf8b-440e-9420-4198080d06c8-0', tool_calls=[{'name': 'func1', 'args': {'i': 1.0}, 'id': '841cf0b2-d48f-43b4-bb8d-7e87dfab9e27', 'type': 'tool_call'}], usage_metadata={'input_tokens': 42, 'output_tokens': 3, 'total_tokens': 45, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "#The display function is used to nicely present outputs within a Jupyter Notebook environment.\n",
        "\n",
        "ai_msg = llm_tools.invoke(\"What is func1 for 1\")\n",
        "display(ai_msg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "butUqgv95WPy",
        "outputId": "9248c8f0-c17f-4a2f-e2ef-348d206337c3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'name': 'func1', 'arguments': '{\"i\": 1.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-9822fb2f-6bd8-4355-a7d2-60dee1bbea7a-0', tool_calls=[{'name': 'func1', 'args': {'i': 1.0}, 'id': 'a8c44a39-841a-43e8-b5da-ae27dec35cd9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 42, 'output_tokens': 3, 'total_tokens': 45, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create message(Prompts & Responses) history\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "query = \"What is func1 for 1\"\n",
        "messages = [HumanMessage(query)]\n",
        "display(messages)\n",
        "#4 kinds of messages: Human message, System message, AI message, Tool message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "nLqCwRsO6h9w",
        "outputId": "047b53ce-e4e6-4c3a-9a25-3178af3349ad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[HumanMessage(content='What is func1 for 1', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ai_msg_tools = llm_tools.invoke(messages)\n",
        "messages.append(ai_msg_tools)\n",
        "display(messages)\n",
        "# Remember messages is our list of messages in the conversation? This line adds\n",
        "# the LLM's response (ai_msg_tools) to that list. So now messages has both our\n",
        "# original query and the LLM's answer. This is useful for keeping track of the conversation history."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "mAQdwYl565KJ",
        "outputId": "58db0650-42d7-4d29-844f-0f86c8058330"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[HumanMessage(content='What is func1 for 1', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'function_call': {'name': 'func1', 'arguments': '{\"i\": 1.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-28d4d41a-2deb-4122-877d-1bae785a8665-0', tool_calls=[{'name': 'func1', 'args': {'i': 1.0}, 'id': '189a3db3-dc94-4a1c-8080-0fd2b5826d32', 'type': 'tool_call'}], usage_metadata={'input_tokens': 42, 'output_tokens': 3, 'total_tokens': 45, 'input_token_details': {'cache_read': 0}})]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ai_msg_tools.tool_calls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gTUO6fII21R",
        "outputId": "db49757f-30a8-4064-c006-9f4e3483f564"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'func1',\n",
              "  'args': {'i': 1.0},\n",
              "  'id': '189a3db3-dc94-4a1c-8080-0fd2b5826d32',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Finally to get AI message, in this case tool message, which will be passed to llm:\n",
        "for tool_call in ai_msg_tools.tool_calls:\n",
        "    selected_tool = {\n",
        "        \"func1\": func1,\n",
        "       #add more tools\n",
        "      }[tool_call[\"name\"].lower()]\n",
        "    tool_msg = selected_tool.invoke(tool_call)\n",
        "    display(tool_msg)\n",
        "    messages.append(tool_msg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "uYSXsN_4JRrR",
        "outputId": "97d60496-62f6-49d9-bb41-7d139840d48c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ToolMessage(content='6.0', name='func1', tool_call_id='189a3db3-dc94-4a1c-8080-0fd2b5826d32')"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(messages)\n",
        "#prompt (human message) and tool message is now saved in messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "oqAKy53UKKgg",
        "outputId": "333b7ddf-cb06-4a4c-eba7-af303c446753"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[HumanMessage(content='What is func1 for 1', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'function_call': {'name': 'func1', 'arguments': '{\"i\": 1.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-28d4d41a-2deb-4122-877d-1bae785a8665-0', tool_calls=[{'name': 'func1', 'args': {'i': 1.0}, 'id': '189a3db3-dc94-4a1c-8080-0fd2b5826d32', 'type': 'tool_call'}], usage_metadata={'input_tokens': 42, 'output_tokens': 3, 'total_tokens': 45, 'input_token_details': {'cache_read': 0}}),\n",
              " ToolMessage(content='6.0', name='func1', tool_call_id='189a3db3-dc94-4a1c-8080-0fd2b5826d32')]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoke the llm with messages\n",
        "response = llm_tools.invoke(messages)\n",
        "messages.append(response)"
      ],
      "metadata": {
        "id": "5F1LtI9uKVi5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for a nice display format\n",
        "from IPython.display import Markdown\n",
        "\n",
        "Markdown(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "scRh9b4rKiTn",
        "outputId": "bb96a20c-caab-4131-c9be-6439aba60521"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "func1 for 1 returns `{\"func1_response\": \"{\"output\": 6}\"}`."
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "kj8Zb4myRt1j",
        "outputId": "53cbe410-5df5-41f9-d9bc-48ecd7c18581"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[HumanMessage(content='What is func1 for 1', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'function_call': {'name': 'func1', 'arguments': '{\"i\": 1.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-28d4d41a-2deb-4122-877d-1bae785a8665-0', tool_calls=[{'name': 'func1', 'args': {'i': 1.0}, 'id': '189a3db3-dc94-4a1c-8080-0fd2b5826d32', 'type': 'tool_call'}], usage_metadata={'input_tokens': 42, 'output_tokens': 3, 'total_tokens': 45, 'input_token_details': {'cache_read': 0}}),\n",
              " ToolMessage(content='6.0', name='func1', tool_call_id='189a3db3-dc94-4a1c-8080-0fd2b5826d32'),\n",
              " AIMessage(content='func1 for 1 returns `{\"func1_response\": \"{\"output\": 6}\"}`.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-ff781a06-536f-4859-ac57-e8356c80c25f-0', usage_metadata={'input_tokens': 72, 'output_tokens': 23, 'total_tokens': 95, 'input_token_details': {'cache_read': 0}})]"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}